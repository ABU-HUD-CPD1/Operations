# -*- coding: utf-8 -*-
"""
Created on Wed Feb 12 15:02:20 2025

Urban County Notice Attachments A-F

This Python script generates attachments A-F for the urban county requalification notice. 
It reads data from a current "MERGE.xlsx", processes it, and then exports the results to a new 
Excel file with multiple sheets. This requires the most recent MERGE file, OMB MSA x County file,
Census Population Estimates, and on output location.

@author: H45562
"""

## User Input () Define Input/Output File Locations
MERGE_Location = 'J:/COMS/MERGE/MERGE FY25/MERGE.xlsx'
OMBList1_Location='J:/COMS/Data and Program Library/OMB Data/2023 July/list1_2023.xlsx' #This is the MSA x County List from OMB.
Census_Population_Estimates_File_Location= 'J:/COMS/POP/2023/sub-est2023.csv'  #CSV format from Census
OutputFolder = 'C:/Users/H45562/Desktop/New folder/'  #Ends with /
OutputFilename = 'UC_Requalification_Attachments.xlsx'

import pandas as pd
import numpy as np  # Import NumPy

# Import data with appropriate converters and skiprows (adjust as needed)
try:
    MERGE = pd.read_excel(MERGE_Location, converters={'CDBGTY': str, 'CDBGHPL': str, 'ST': str, 'CO': str, 'UC': str, 'MA': str, 'RGN': str, 'FO': str, 'CYCLE': str, 'AGL': str})
except FileNotFoundError:
    print(f"Error: MERGE file not found at {MERGE_Location}")
    exit()
try:
    OMBList1 = pd.read_excel(OMBList1_Location, converters={'CBSA Code': str, 'Metropolitan Division Code': str, 'FIPS State Code': str, 'FIPS County Code': str}, skiprows=2)  # Skip first 2 rows
except FileNotFoundError:
    print(f"Error: OMB List 1 file not found at {OMBList1_Location}")
    exit()

try:
    Pop = pd.read_csv(Census_Population_Estimates_File_Location, converters={'SUMLEV': str, 'STATE': str, 'COUNTY': str, 'PLACE': str, 'COUSUB': str, 'CONCIT': str, 'PRIMGEO_FLAG': str}, engine='python', encoding='latin1')
except FileNotFoundError:
    print(f"Error: Census Population file not found at {Census_Population_Estimates_File_Location}")
    exit()

federal_regions = {
    "01": "New England",  
    "02": "New York/New Jersey", 
    "03": "Mid-Atlantic",  
    "04": "Southeast/Caribbean",  
    "05": "Midwest",  
    "06": "Southwest",  
    "07": "Great Plains",   
    "08": "Rocky Mountain",  
    "09": "Pacific/Hawaii",  
    "10": "Northwest/Alaska",   
}

# this list excludes Nashville-Davidson metropolitan government (balance), TN; Washington city, DC; Athens-Clarke County unified government (balance), GA; Augusta-Richmond County consolidated government (balance), GA; Columbus city, GA; Urban Honolulu CDP, HI; Indianapolis city (balance), IN; Lexington-Fayette urban county, KY; Louisville/Jefferson County metro government (balance), KY; Baton Rouge city, LA; Houma city, LA; Lafayette city, LA; Baltimore city, MD
CitiesToSkip= ('4752006','1150000','1303440','1304204','1319000','1571550','1836003','2146027','2148006','2205000','2236255','2240735','2404000', '2203399990', "2205599990")

State_Abbreviations = {
    'STA': ['AL', 'AK', 'AZ', 'AR', 'CA', 'CO', 'CT', 'DE', 'DC', 'FL', 'GA', 'HI', 'ID', 'IL', 'IN', 'IA', 'KS', 'KY', 'LA', 'ME', 'MD', 'MA', 'MI', 'MN', 'MS', 'MO', 'MT', 'NE', 'NV', 'NH', 'NJ', 'NM', 'NY', 'NC', 'ND', 'OH', 'OK', 'OR', 'PA', 'RI', 'SC', 'SD', 'TN', 'TX', 'UT', 'VT', 'VA', 'WA', 'WV', 'WI', 'WY', 'AS', 'GU', 'MP', 'PR', 'VI'],
    'FIPS': ['01', '02', '04', '05', '06', '08', '09', '10', '11', '12', '13', '15', '16', '17', '18', '19', '20', '21', '22', '23', '24', '25', '26', '27', '28', '29', '30', '31', '32', '33', '34', '35', '36', '37', '38', '39', '40', '41', '42', '44', '45', '46', '47', '48', '49', '50', '51', '53', '54', '55', '56', '60', '66', '69', '72', '78']
}

# Convert the dictionary to a DataFrame directly (much simpler):
df_regions = pd.DataFrame.from_dict(federal_regions, orient='index', columns=['Region'])
df_regions.index.name = 'RGN'  # Set the index name to RGN

#Create Dataframe of all currently qualified Urban Counties
AllUrbanCounties = MERGE[(MERGE['CDBGTY'] == '61') & (MERGE['CDBGFLAG'] == 'C')]
#Drop Louisville KY Record
AllUrbanCounties = AllUrbanCounties.drop(AllUrbanCounties[(AllUrbanCounties['CDBGHPL'] == '9111') & (AllUrbanCounties['ST'] == '21')].index)
#Add Region Names
AllUrbanCounties = AllUrbanCounties.merge(df_regions, on=['RGN'], how='left')
#Create Dataframes of Urban Counties by their Cycle
AllUrbanCountiesUC1 = AllUrbanCounties[(AllUrbanCounties['CDBGTY'] == '61') & (AllUrbanCounties['CDBGFLAG'] == 'C') & (AllUrbanCounties['CYCLE'] == '1')]
AllUrbanCountiesUC2 = AllUrbanCounties[(AllUrbanCounties['CDBGTY'] == '61') & (AllUrbanCounties['CDBGFLAG'] == 'C') & (AllUrbanCounties['CYCLE'] == '2')]
AllUrbanCountiesUC3 = AllUrbanCounties[(AllUrbanCounties['CDBGTY'] == '61') & (AllUrbanCounties['CDBGFLAG'] == 'C') & (AllUrbanCounties['CYCLE'] == '3')]
#Create Dataframe of Counties with Non-participating commmunicites
NonParticipatingCommunities = MERGE[(MERGE['CDBGTY'] == '64') & (MERGE['UC'] == '3')]
CountiesWithNonParticipatingPlaces = AllUrbanCounties[(AllUrbanCounties['ST'].isin(NonParticipatingCommunities['ST'])) & (AllUrbanCounties['CDBGHPL'].isin(NonParticipatingCommunities['CDBGHPL']))]

def generate_AttachmentA(df):
    """
   Generates a formatted report of counties grouped by region and state,
   sorted by RGN and STATEBREAK codes.

    Args:
      df: pandas DataFrame with Counties for the report containing columns "RGN, "Region', 'STATEBREAK', and 'NAME'.

    Returns:
      A formatted string representing the report.
    """

    report = "All Currently Qualified Urban Counties\n\n"

    # Sort the DataFrame by RGN and FO
    df_sorted = df.sort_values(by=['RGN', 'STATEBREAK', 'NAME'], ascending=[True, True, True])  # Sort by RGN, then FO

    for rgn, rgn_df in df_sorted.groupby('RGN'):  # Group by RGN first
        for region, region_df in rgn_df.groupby('Region'): # Then, within each RGN group, group by Region
            report += f"{region} Field Offices\n\n"
            for state, state_df in region_df.groupby('STATEBREAK'):
                for county in state_df['NAME']+",":
                    report += f"{county}\t{state}\n"
                report += "\n"
           

    return report

def generate_Cycle1(df):
    """
    Generates a formatted report of counties grouped by region and state,
    sorted by RGN and STATEBREAK codes.

    Args:
      df: pandas DataFrame with Counties for the report containing columns "RGN, "Region', 'STATEBREAK', and 'NAME'.

    Returns:
      A formatted string representing the report.
    """

    report = "Counties Scheduled To Requalify In Cycle=1 For FYs 20xx-20xx \n\n"

    # Sort the DataFrame by RGN and FO
    df_sorted = df.sort_values(by=['RGN', 'STATEBREAK', 'NAME'])  # Sort by RGN, then FO

    for rgn, rgn_df in df_sorted.groupby('RGN'):  # Group by RGN first
        for region, region_df in rgn_df.groupby('Region'): # Then, within each RGN group, group by Region
            report += f"{region} Field Offices\n\n"
            for state, state_df in region_df.groupby('STATEBREAK'):
                for county in state_df['NAME']+",":
                    report += f"{county}\t{state}\n"
                report += "\n"
            

    return report

def generate_Cycle2(df):
    """
    Generates a formatted report of counties grouped by region and state,
    sorted by RGN and STATEBREAK codes.

    Args:
      df: pandas DataFrame with Counties for the report containing columns "RGN, "Region', 'STATEBREAK', and 'NAME'.

    Returns:
      A formatted string representing the report.
    """

    report = "Counties Scheduled To Requalify In Cycle=2 For FYs 20xx-20xx\n\n"

    # Sort the DataFrame by RGN and FO
    df_sorted = df.sort_values(by=['RGN', 'STATEBREAK', 'NAME'])  # Sort by RGN, then FO

    for rgn, rgn_df in df_sorted.groupby('RGN'):  # Group by RGN first
        for region, region_df in rgn_df.groupby('Region'): # Then, within each RGN group, group by Region
            report += f"{region} Field Offices\n\n"
            for state, state_df in region_df.groupby('STATEBREAK'):
                for county in state_df['NAME']+",":
                    report += f"{county}\t{state}\n"
                report += "\n"
            

    return report

def generate_Cycle3(df):
    """
    Generates a formatted report of counties grouped by region and state,
    sorted by RGN and STATEBREAK codes.

    Args:
      df: pandas DataFrame with Counties for the report containing columns "RGN, "Region', 'STATEBREAK', and 'NAME'.

    Returns:
      A formatted string representing the report.
    """

    report = "Counties Scheduled To Requalify In Cycle=3 For FYs 20xx-20xx\n\n"

    # Sort the DataFrame by RGN and FO
    df_sorted = df.sort_values(by=['RGN', 'STATEBREAK', 'NAME'])  # Sort by RGN, then FO
    for rgn, rgn_df in df_sorted.groupby('RGN'):  # Group by RGN first
        for region, region_df in rgn_df.groupby('Region'): # Then, within each RGN group, group by Region
            report += f"{region} Field Offices\n\n"
            for state, state_df in region_df.groupby('STATEBREAK'):
                for county in state_df['NAME']+",":
                    report += f"{county}\t{state}\n"
                report += "\n"
           

    return report


def generate_AttachmentE(df):
    """
    Generates a formatted report of counties grouped by region and state,
    sorted by RGN and STATEBREAK codes.

    Args:
      df: pandas DataFrame with Counties for the report containing columns "RGN, "Region', 'STATEBREAK', and 'NAME'.

    Returns:
      A formatted string representing the report.
    """

    report = "Counties Qualified Through 20xx or 20xx That Contain Non-Participating Communities\n\n"

    # Sort the DataFrame by RGN and FO
    df_sorted = df.sort_values(by=['RGN', 'STATEBREAK', 'NAME'])  # Sort by RGN, then FO
    for rgn, rgn_df in df_sorted.groupby('RGN'):  # Group by RGN first
        for region, region_df in rgn_df.groupby('Region'): # Then, within each RGN group, group by Region
            report += f"{region} Field Offices\n\n"
            for state, state_df in region_df.groupby('STATEBREAK'):
                for county in state_df['NAME']+",":
                    report += f"{county}\t{state}\n"
                report += "\n"
            

    return report

# Generate the reportS
AttachmentA = generate_AttachmentA(AllUrbanCounties)
Cycle1 = generate_Cycle1(AllUrbanCountiesUC1)
Cycle2 = generate_Cycle2(AllUrbanCountiesUC2)
Cycle3 = generate_Cycle3(AllUrbanCountiesUC3)
AttachmentE = generate_AttachmentE(CountiesWithNonParticipatingPlaces)

def string_to_dataframe(data_string, delimiter=",", column_names=None):
    """Converts a delimited string to a Pandas DataFrame.

    Args:
        data_string: The string data.
        delimiter: The delimiter character (default is ".").
        column_names: A list of column names (optional). If None, default numeric column names will be used.

    Returns:
        A Pandas DataFrame, or None if an error occurs.
    """
    try:
        # 1. Split into rows
        rows = data_string.strip().splitlines()

        # 2. Split each row into values
        data = []
        for row in rows:
            values = row.split(delimiter)
            data.append(values)

        # 3. Create DataFrame
        df = pd.DataFrame(data, columns=column_names) # uses the column_names if provided

        return df

    except Exception as e:
        print(f"Error converting string to DataFrame: {e}")
        return None

#Convert String Repots to Dataframes
AttachmentA=string_to_dataframe(AttachmentA)
Cycle1=string_to_dataframe(Cycle1)
Cycle2=string_to_dataframe(Cycle2)
Cycle3=string_to_dataframe(Cycle3)
AttachmentE=string_to_dataframe(AttachmentE)

#Clean up State names to remove extra white space
AttachmentA = AttachmentA.rename(columns={0: 'NAME', 1: 'STATEBREAK'}) # Name Columns
AttachmentA['STATEBREAK'] = AttachmentA['STATEBREAK'].str.strip()  # Removes leading/trailing whitespace
Cycle1 = Cycle1.rename(columns={0: 'NAME', 1: 'STATEBREAK'}) # Name Columns
Cycle1['STATEBREAK'] = Cycle1['STATEBREAK'].str.strip()  # Removes leading/trailing whitespace
Cycle2 = Cycle2.rename(columns={0: 'NAME', 1: 'STATEBREAK'}) # Name Columns
Cycle2['STATEBREAK'] = Cycle2['STATEBREAK'].str.strip()  # Removes leading/trailing whitespace
Cycle3 = Cycle3.rename(columns={0: 'NAME', 1: 'STATEBREAK'}) # Name Columns
Cycle3['STATEBREAK'] = Cycle3['STATEBREAK'].str.strip()  # Removes leading/trailing whitespace
AttachmentE = AttachmentE.rename(columns={0: 'NAME', 1: 'STATEBREAK'}) # Name Columns
AttachmentE['STATEBREAK'] = AttachmentE['STATEBREAK'].str.strip()  # Removes leading/trailing whitespace

##Add Cycles codes to Attachment E
# Create a subset of AllUrbanCounties with only the needed columns
subset_df = AllUrbanCounties[['NAME', 'STATEBREAK', 'CYCLE']]
AttachmentE = AttachmentE.merge(subset_df, on=['NAME', 'STATEBREAK'], how='left')

MERGEc=MERGE
## Data Correct MERGEc
MERGEc.loc[MERGEc['MCD'] == "00000",'MCD']="99999"
MERGEc.loc[MERGEc['PLACE'] == "00000",'PLACE']="99999"
MERGEc.loc[MERGEc['PLACE'] == "99990",'PLACE']="99999"
MERGEc['UCKEY']=MERGEc['ST']+MERGEc['CDBGHPL']

MERGEc['UCKEY'] = MERGEc["ST"]+MERGEc["CDBGHPL"]
MERGEc.loc[MERGEc['PLACE'] == MERGEc['MCD'],'MCD']="99999"
###Create Note column
MERGEc['Note'] = MERGEc['CDBGTY'].where(MERGEc['CDBGTY'].isin(["51", "52"]), np.nan)  # Or a default value
###Add UC Names to participating records in MERGEc
ucname_mapping = MERGEc.loc[MERGEc['CDBGTY'] == "61"].set_index(['ST', 'CDBGHPL'])['NAME'].to_dict()
MERGEc.loc[(MERGEc['CDBGTY'] == "64") & (MERGEc['UC'] == "1"), 'UCName'] = MERGEc.loc[(MERGEc['CDBGTY'] == "64") & (MERGEc['UC'] == "1")].set_index(['ST', 'CDBGHPL']).index.map(ucname_mapping)
MERGEc.loc[(MERGEc['CDBGTY'] == "63") & (MERGEc['UC'] == "4"), 'UCName'] = MERGEc.loc[(MERGEc['CDBGTY'] == "63") & (MERGEc['UC'] == "4")].set_index(['ST', 'CDBGHPL']).index.map(ucname_mapping)

#Re-assign Fields as needed
OMBList1 = OMBList1.assign(MA="",STATECOUNTY="")
OMBList1 = OMBList1.assign(FIPSKEY="", PCFlag="PC")
Pop = Pop.assign( FIPSKEY="", STATECOUNTY="")
OMBList1['MA'] = OMBList1['Metropolitan Division Code'].where(OMBList1['Metropolitan Division Code'].notnull(), OMBList1['CBSA Code'])

# Find columns in pop file starting with 'POPESTIMATE'
pop_estimate_cols = [col for col in Pop.columns if col.startswith('POPESTIMATE')]
if pop_estimate_cols:
    # Extract the year from the column names
    years = [int(col.replace('POPESTIMATE', '')) for col in pop_estimate_cols]
    # Find the column with the latest year
    latest_year_col = pop_estimate_cols[years.index(max(years))]
    # Rename the latest year column to 'POP'
    Pop = Pop.rename(columns={latest_year_col: 'POP'})

# Update Fipskeys in pop file
Pop.loc[Pop['SUMLEV'] == '040', ['FIPSKEY']] = Pop["STATE"]
Pop.loc[Pop['SUMLEV'] == '050', ['FIPSKEY']] = Pop["STATE"]+Pop["COUNTY"]
Pop.loc[Pop['SUMLEV'] == '061', ['FIPSKEY']] = Pop["STATE"]+Pop["COUNTY"]+Pop["COUSUB"]
Pop.loc[Pop['SUMLEV'] == '071', ['FIPSKEY']] = Pop["STATE"]+Pop["COUNTY"]+Pop["PLACE"]
Pop.loc[(Pop['SUMLEV'] == '071')&(Pop['PLACE'] == '99990'), ['FIPSKEY']] = Pop["STATE"]+Pop["COUNTY"]+Pop["COUSUB"]+Pop["PLACE"]
Pop.loc[Pop['SUMLEV'] == '157', ['FIPSKEY']] = Pop["STATE"]+Pop["COUNTY"]+Pop["PLACE"]
Pop.loc[Pop['SUMLEV'] == '162', ['FIPSKEY']] = Pop["STATE"]+Pop["PLACE"]
Pop.loc[Pop['SUMLEV'] == '170', ['FIPSKEY']] = Pop["STATE"]+Pop["CONCIT"]
Pop['STATECOUNTY'] = Pop["STATE"]+Pop["COUNTY"]
OMBList1['STATECOUNTY'] = OMBList1["FIPS State Code"]+OMBList1["FIPS County Code"]

### Start Making Attachment F 
# Primary Geography Flag = 1. Thanks Census for the easy to use flag. Make sure it has some population
AttachmentF = Pop[Pop['PRIMGEO_FLAG'] == "1"]
AttachmentF = AttachmentF[AttachmentF['POP']!= 0]

#Remove micropolitan areas from list 1 and list 2
OMBList1 = OMBList1[OMBList1['Metropolitan/Micropolitan Statistical Area']!= 'Micropolitan Statistical Area']
#OMBList2 = OMBList2[OMBList2['Metropolitan/Micropolitan Statistical Area']!= 'Micropolitan Statistical Area']

#Fipskey Data
AttachmentF.loc[AttachmentF['SUMLEV'] == "157", 'FIPSKEY'] = AttachmentF.loc[AttachmentF['SUMLEV'] == "157", 'STATE'] + AttachmentF.loc[AttachmentF['SUMLEV'] == "157", 'PLACE']
AttachmentF.loc[AttachmentF['SUMLEV'] == "071", 'FIPSKEY'] = AttachmentF.loc[AttachmentF['SUMLEV'] == "071", 'STATE'] + AttachmentF.loc[AttachmentF['SUMLEV'] == "071", 'PLACE']
AttachmentF.loc[AttachmentF['SUMLEV'] == "061", 'FIPSKEY'] = AttachmentF.loc[AttachmentF['SUMLEV'] == "061", 'STATE'] + AttachmentF.loc[AttachmentF['SUMLEV'] == "061", 'COUNTY'] + AttachmentF.loc[AttachmentF['SUMLEV'] == "061", 'COUSUB']
AttachmentF.loc[(AttachmentF['SUMLEV'] == '071') & (AttachmentF['NAME'].str.startswith('Balance of')), 'FIPSKEY'] = AttachmentF['STATE'].astype(str) + AttachmentF['COUNTY'].astype(str) + AttachmentF['COUSUB'].astype(str) + AttachmentF['PLACE'].astype(str)

# Match to OMB County list and designate MSA area. 
OMBList1.loc[OMBList1['Metropolitan Division Title'].notnull(), 'CBSA Title'] = OMBList1.loc[OMBList1['Metropolitan Division Title'].notnull(), 'Metropolitan Division Title']
AttachmentF = pd.merge(AttachmentF, OMBList1[OMBList1['Metropolitan/Micropolitan Statistical Area'] == 'Metropolitan Statistical Area'][['STATECOUNTY', 'MA', 'CBSA Title']], on='STATECOUNTY', how='left')

### Add County Names
AttachmentF = pd.merge(AttachmentF, Pop.loc[Pop['SUMLEV'] == "050", ['STATE', 'COUNTY', "NAME"]].rename(columns={"NAME":"CountyName"}), how='left', on=['STATE', 'COUNTY'])

##### Mark Places Currently Entitled
## Mark 51s
AttachmentF = pd.merge(AttachmentF, MERGEc.loc[MERGEc['CDBGTY'] == "51", ['ST', 'PLACE', 'Note']].rename(columns={"ST":"STATE"}), how='left', on=['STATE', 'PLACE'])
## Mark 52s
AttachmentF = pd.merge(AttachmentF, MERGEc.loc[MERGEc['CDBGTY'] == "52", ['ST', 'PLACE', 'Note']].rename(columns={"ST":"STATE"}), how='left', on=['STATE', 'PLACE'], suffixes=('', '_52'))
AttachmentF['Note'] = AttachmentF['Note'].fillna(AttachmentF['Note_52'])
AttachmentF = AttachmentF.drop(columns=['Note_52'])
##Mark 51s by ST+CO+MCD
AttachmentF = pd.merge(AttachmentF, MERGEc.loc[MERGEc['CDBGTY'] == "51", ['ST', 'CO', 'MCD', 'Note']].rename(columns={'ST':"STATE", "CO":"COUNTY", "MCD":"COUSUB"}), how='left', on=['STATE', 'COUNTY', 'COUSUB',], suffixes=('', '_TEMP'))
AttachmentF['Note'] = AttachmentF['Note'].fillna(AttachmentF['Note_TEMP'])
AttachmentF = AttachmentF.drop(columns=['Note_TEMP'])
##Mark 52s by ST+CO+MCD
AttachmentF = pd.merge(AttachmentF, MERGEc.loc[MERGEc['CDBGTY'] == "52", ['ST', 'CO', 'MCD', 'Note']].rename(columns={'ST':"STATE", "CO":"COUNTY", "MCD":"COUSUB"}), how='left', on=['STATE', 'COUNTY', 'COUSUB',], suffixes=('', '_TEMP'))
AttachmentF['Note'] = AttachmentF['Note'].fillna(AttachmentF['Note_TEMP'])
AttachmentF = AttachmentF.drop(columns=['Note_TEMP'])

#Make all mark codes X
AttachmentF['Note'] = AttachmentF['Note'].apply(lambda x: 'X' if pd.notna(x) else x)
#Remove Counties not in MSA
AttachmentF.dropna(subset=['MA'], inplace=True)
##Add County Pop Total
AttachmentF = AttachmentF.merge(Pop[Pop['SUMLEV'] == '050'][['STATECOUNTY', 'POP']].rename(columns={'POP': 'PopTotal'}), on='STATECOUNTY', how='left')
### Drop Duplicate rows
AttachmentF = AttachmentF.drop_duplicates()

#Calculate county populations minute metro cities within

# Step 1: Calculate the sums for records where Note is NaN
pop_sums = AttachmentF[AttachmentF['Note'].isnull()].groupby('STATECOUNTY')['POP'].sum().reset_index()
# Step 1: Re-name the column
pop_sums = pop_sums.rename(columns={'POP': 'EligibilePop'})
# Step 3: Merge the sums back into the original DataFrame
AttachmentF = AttachmentF.merge(pop_sums, on='STATECOUNTY', how='left')

#Remove records where PopTotal > 200000 and EligibilePop < 200000
AttachmentF = AttachmentF.drop(AttachmentF[(AttachmentF['PopTotal'] < 200000)].index)
AttachmentF = AttachmentF.drop(AttachmentF[(AttachmentF['EligibilePop'] > 200000)].index)
AttachmentF.dropna(subset=['EligibilePop'], inplace=True)
#remove all records not an entitlement
AttachmentF = AttachmentF[AttachmentF['Note'] == 'X']



###Pull all town total records from MERGE
EntitledTowns= MERGEc[((MERGEc['CDBGTY'] == "51") | (MERGEc['CDBGTY'] == "52")) & (MERGEc['MCDFLAG'] == "T")].copy()
AttachmentF['TOWNFIPS']= AttachmentF['STATE']+AttachmentF['COUNTY']+AttachmentF['COUSUB']
EntitledTowns['TOWNFIPS']=EntitledTowns['FIPSKEY']
AttachmentF['NAME'] = AttachmentF['TOWNFIPS'].map(EntitledTowns.set_index('TOWNFIPS')['NAME']).fillna(AttachmentF['NAME'])


###Indent Name
AttachmentF['NAME'] = "   " + AttachmentF['NAME']




###Append County totals
pop_filtered = Pop[Pop['SUMLEV'] == '050']
AttachmentF = pd.concat([AttachmentF, pop_filtered[pop_filtered['STATECOUNTY'].isin(AttachmentF['STATECOUNTY'])]], ignore_index=True)

###Add state abbreviations
AttachmentF['STA'] = AttachmentF['FIPSKEY'].astype(str).str[:2].map(dict(zip(State_Abbreviations['FIPS'], State_Abbreviations['STA'])))

####Sort
AttachmentF = AttachmentF.sort_values(by=['STA', 'COUNTY', 'COUSUB', 'PLACE' ], ascending=[True, True, True, True])
###Remove Current Urban Counties
AllUrbanCounties = AllUrbanCounties.rename(columns={'CO': 'COUNTY'})
AllUrbanCounties = AllUrbanCounties.rename(columns={'ST': 'STATE'})
AttachmentF = AttachmentF[~AttachmentF[['STATE', 'COUNTY']].apply(tuple, axis=1).isin(AllUrbanCounties[['STATE', 'COUNTY']].apply(tuple, axis=1))]

AttachmentF = AttachmentF.sort_values(by=['STA', 'COUNTY', 'PLACE', 'COUSUB'], ascending=[True, True, True, True])
###Clean up and reorder columns.
#Make it look exactly like the last time
AttachmentF = AttachmentF[["STA","NAME","POP",'STATECOUNTY']]

###Sum Pop
AttachmentF = AttachmentF.groupby(['NAME', 'STA', 'STATECOUNTY'], sort=False)['POP'].sum().reset_index()
#AttachmentF = AttachmentF.sort_values(by=['STA', 'STATECOUNTY', 'NAME', ], ascending=[True, True, True])
AttachmentF = AttachmentF[["STA", "NAME", "POP"]]
#Rename Pop Columns back to original titles
AttachmentF = AttachmentF.rename(columns={'POP': latest_year_col}) # Where latest_year_col is the original name

# Remove States with No County Gov
AttachmentF = AttachmentF[AttachmentF["STA"] != "CT"]

### Drop Duplicate rows
AttachmentF = AttachmentF.drop_duplicates()

#####Export File
report_name = "List Of Counties That May Qualify As Urban Counties If Metropolitan Cities Relinquish Their Status\n\n"
blank_header = pd.DataFrame([[''] * len(AttachmentF.columns)], columns=AttachmentF.columns)

###Export Reports
with pd.ExcelWriter(OutputFolder+OutputFilename) as writer:
    AttachmentA.to_excel(writer, sheet_name='Attachment A', header=False, index=False)
    Cycle1.to_excel(writer, sheet_name='Attachment Cycle=1', header=False, index=False)
    Cycle2.to_excel(writer, sheet_name='Attachment Cycle=2', header=False, index=False)
    Cycle3.to_excel(writer, sheet_name='Attachment Cycle=3', header=False, index=False)
    AttachmentE.to_excel(writer, sheet_name='Attachment E', header=False, index=False)
    # Write the header
    pd.DataFrame({'Header': [report_name]}).to_excel(writer, sheet_name='Attachment F', index=False, header=False)
    #Write the blank Row
    #blank_header.to_excel(writer, sheet_name='Attachment F', index=False, startrow=2, header=False)
    # Write the DataFrame (starting from the second row)
    AttachmentF.to_excel(writer, sheet_name='Attachment F', index=False, startrow=2)  # Start from row 1 (second row) for data